<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name=”Keywords” Content=”design,creat,设计,山合,picture,图片,art,艺术,blog,博客,pan,eBook,软件,电子书免费,PS,photoshop,pdf,好物分享,电影,美文″>
    <title>SAMHO Club</title>
    <meta property="og:type" content="article"/>
<meta property="og:image" content="images/blog-7.jpg"/>
<meta property="og:release_date" content="2020-12-20"/>
<!--选填-->
<meta property="og:title" content="友情留言板留言大全"/>
<meta property="og:description" content="友情留言板留言大全经典语句,资料来自:parents"/>
    <meta name="description" content="Your Image page description"/>
    <link href="https://fonts.googleapis.com/css?family=Arimo:400,600,700" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link rel="shortcut icon" type="image/png" href="images/favicon.png">
    <link href="styles/main.css" rel="stylesheet">
  </head>
  <body id="top">
    <div class="page">
      <header>
        <div class="pp-header">
          <nav class="navbar navbar-expand-lg navbar-light">
            <div class="container"><a href="index.html"><img src="images/favicon.png"></a><a class="navbar-brand" href="index.html">SAMHO Club</a>
              <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
              <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
                <ul class="navbar-nav ml-auto">
                  <li class="nav-item"><a class="nav-link" href="index.html">Home</a>
                  </li>
                  <li class="nav-item"><a class="nav-link" href="about.html">About</a>
                  </li>
                  <li class="nav-item"><a class="nav-link" href="blog.html">Blog</a>
                  </li>
                  <li class="nav-item"><a class="nav-link" href="video.html">video</a>
                  </li>
                  <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a>
                  </li>
                </ul>
              </div>
            </div>
          </nav>
        </div>
      </header>
      <div class="page-content">
        <div class="container">
<div class="container pp-section">
  <div class="h3 font-weight-normal">How Misinformation Spreads—and Why We Trust It</div><img class="img-fluid mt-4" src="images/blog-7.jpg"/>
  <div class="row mt-5">
    <div class="col-md-3">
      <div class="h5">Tags</div><a class="mr-1 badge badge-primary" href="#">psychology</a><a class="mr-1 badge badge-primary" href="#">Sociology</a><a class="badge badge-primary" href="#">Covid-19</a>
      <div class="h5 pt-4">Year</div>
      <p>2020</p>
    </div>
    <div class="col-md-9">
      <p>在19世纪中叶，一只像人类手指一样大小的毛毛虫开始在美国东北部蔓延。番茄角虫的出现之后，出现了关于致命中毒和对人攻击性行为的可怕报道。1869年7月，整个地区的报纸都刊登了关于这种昆虫的警告，报道说，纽约州红溪的一个女孩在与这种昆虫发生冲突后，"被扔进痉挛，最后以死亡结束"。那年秋天，锡拉丘兹标准印了一个富勒博士的叙述，他收集了一个特别巨大的标本。医生警告说，毛毛虫"像响尾蛇一样有毒"，并说他知道有三起死亡与它的毒液有关。<br>

虽然角虫是一种贪婪的食客，可以在几天内剥去番茄植物，但事实上，它对人类无害。数十年来，当富勒发表他的戏剧性报道时，昆虫学家们已经知道这种昆虫是无害的，他的说法受到专家的广泛嘲笑。那么，为什么谣言会持续，即使真相是现成的呢？人都是社会学习者。我们从值得信赖的其他人（如我们的老师、父母和朋友）的见证中发展出我们大部分的信仰。这种知识的社会传播是文化和科学的核心。但正如番茄角虫的故事告诉我们的，我们的能力有一个漏洞：有时我们传播的想法是错误的。<br>
过去五年来，知识的社会传播使我们失败的方式成为人们关注的焦点。社交媒体网站上分享的错误信息助长了错误信仰的流行，对选民欺诈的流行、桑迪胡克校园枪击案是否上演、疫苗是否安全等话题存在广泛的误解。传播对番茄角虫的恐惧的同样基本机制现在已经加剧——在某些情况下，也导致了——公众对基本社会机构的深刻不信任。其中一个后果是一代人中最大的麻疹疫情。<br>
"错误信息"在这里可能看起来是个用词不当。毕竟，当今许多最具破坏性的错误信仰最初是由宣传和造谣行为所驱使的，这些行为是蓄意欺骗的，意在造成伤害。但是，在社交媒体时代，宣传和造谣如此有效的部分原因在于，接触这种信息的人与信任他们的朋友和同龄人广泛分享，无意误导任何人。社交媒体将虚假信息转化为错误信息。

许多传播理论家和社会科学家试图通过将思想的传播建模为一种传染来理解错误信念是如何持续存在的。使用数学模型需要使用计算机算法模拟人类社会交互的简化表示，然后研究这些模拟以了解真实世界。在传染模型中，想法就像从头脑中消失的病毒。从网络开始，该网络由代表个人和边缘的节点组成，这些节点表示社交连接。你在一个"头脑"中种下一个想法，看看它是如何在关于何时传输的各种假设下传播的。<br>
传染模型非常简单，但被用来解释令人惊讶的行为模式，例如，据报道，在1774年《风神报》出版《年轻韦瑟的悲伤》之后，自杀的流行席卷了整个欧洲，或者1962年数十名美国纺织工人报告说，他被假想的昆虫咬伤后，患有恶心和麻木。他们还可以解释一些错误的信念是如何在互联网上传播的。在上次美国总统大选之前，Facebook上出现了一唐纳德·特朗普一张年轻照片。其中包括1998年《人物》杂志的一次采访，其中称如果特朗普曾经竞选总统，那将是共和党，因为该党是由"最愚蠢的选民群体"。虽然不清楚谁是 "病人零"， 我们知道这个 meme 从配置文件迅速传递到配置文件。<br>

模因的真实性很快被评价和揭穿。事实核查网站Snopes报道说，该引文早在2015年10月就被捏造了。但与番茄角虫一样，这些传播真相的努力并没有改变谣言的传播。单是 meme 的一份就被分享了 50 多万次。在接下来的几年里，当新的个人分享它时，他们的错误信仰感染了观察模因的朋友，反过来，他们把错误的信念传递到网络的新领域。</p>
      <p>为了在研究中更好地了解这种行为，我们借鉴了所谓的网络认识论框架。它最初是由经济学家在20年前开发的，以研究信仰在社区中的社会传播。这类模型有两个部分：一个问题和个人网络（或"代理"）。这个问题涉及到选择两种选择之一：这些可能是"接种疫苗"和"不接种疫苗"你的孩子。在模型中，代理对哪个选择更好有信念。一些人认为接种疫苗是安全和有效的，而另一些人则认为接种疫苗会导致自闭症。代理信念塑造了他们的行为——那些认为接种疫苗是安全的人选择接种疫苗。他们的行为反过来又塑造了他们的信仰。当代理人接种疫苗，发现没有坏事发生时，他们更加确信接种疫苗确实是安全的。<br>
        模型的第二部分是表示社会联系的网络。代理人不仅可以从自己的接种疫苗经验中学习，还可以从邻居的经验中学习。因此，一个人的社区在决定他们最终发展什么信仰时非常重要。<br><img class="img-fluid" src="images/blog-8.jpg" alt="Blog Image"/><br>

网络认识论框架捕获了传染模型缺少的一些基本特征：个人故意收集数据、共享数据，然后经历不良信念的后果。这些发现给我们一些有关知识社会传播的重要课程。我们首先学到的是，一起工作比独自工作好，因为一个人面对这样的问题，可能会过早地解决更糟糕的理论。例如，他或她可能会观察一个孩子在接种疫苗后患有自闭症，并得出结论，疫苗不安全。在一个社区里，人们所相信的往往有些不同。一些测试一个操作;一些测试另一个。这种多样性意味着通常收集足够的证据来形成良好的信仰。<br>

但即使是这个群体的利益也不能保证代理人了解真相。当然，真正的科学证据是概率的。例如，一些不吸烟者得肺癌，而一些吸烟者不会患肺癌。这意味着一些对吸烟者的研究会发现与癌症没有关系。与此相关的是，虽然疫苗和自闭症之间没有实际的统计联系，但一些接种疫苗的儿童将是自闭症。因此，一些家长在接种疫苗后观察他们的孩子出现自闭症症状。这种误导性证据的串串可能足以引导整个社区犯错。<br>

在这个模型的最基本版本中，社会影响意味着社区最终形成共识。他们决定要么接种疫苗是安全的，要么说是危险的。但这不符合我们在现实世界中所看到的。在实际社区，我们看到两极分化——在是否接种疫苗的问题上存在根深蒂固的分歧。我们认为，基本模式缺少两个关键要素：社会信任和顺从主义。<br>

当个人认为某些证据来源比其他人更可靠时，社会信任对信仰很重要。当反病毒者信任社区中其他人分享的证据，而不是疾病控制和预防中心或其他医学研究小组提供的证据时，我们就看到了这一点。这种不信任可能源于各种事情，包括以前与医生的负面经历，或担心卫生保健或政府机构不关心他们的最佳利益。在某些情况下，这种不信任可能是合理的，因为长期以来，医学研究人员和临床医生忽视患者，特别是妇女的合法问题。<br>

然而，最终结果是，反病毒者并没有从收集关于这个问题的最佳证据的人那里学习。在模型的版本中，个人不信任那些持有截然不同的信仰的人提供的证据，我们发现社区两极分化，而那些信仰不差的人无法学习更好的信仰。<br>

同时，顺从主义是一种偏好，以与社区中的其他人相同的方式行事。顺从的冲动是人类心灵的深刻部分，也是导致我们采取我们知道有害的行动。当我们在模型中加入顺从论时，我们看到的是持有错误信仰的代理人团体的出现。原因是，与外界有联系的代理人不会传递与团队信仰相冲突的信息，这意味着团队的许多成员从未了解真相。<br>

一致性可以帮助解释为什么疫苗怀疑论者倾向于聚集在某些社区。南加州的一些私立和特许学校的疫苗接种率在两位数以下。明尼阿波利斯的索马里移民和布鲁克林的东正教犹太人的比例都低得惊人——这两个社区最近遭受了麻疹疫情。<br>

对疫苗怀疑的干预措施需要同时对社会信任和一致性保持敏感。由于信任问题，仅仅与怀疑论者分享新证据可能无济于事。说服值得信赖的社区成员大声疾呼接种疫苗可能因为顺从主义而困难重重。最好的方法是找到与相关社区成员有足够共同之处的人来建立信任。例如，拉比可能是布鲁克林的有效疫苗大使，而在南加州，你可能需要让格温妮丝·帕特罗参与进来。<br>

社会信任和一致性有助于解释为什么两极分化的信念会出现在社交网络中。但至少在某些情况下，包括明尼苏达州的索马里社区和纽约的东正教犹太社区，他们只是故事的一部分。这两个团体都是反病毒者设计的复杂错误信息运动的目标。
顺从的冲动是人类心灵的深刻部分，也是导致我们采取我们知道有害的行动。<br>
更糟糕的是，宣传者正在不断开发越来越复杂的方法来操纵公众信仰。在过去的几年里，我们看到造谣者推出新的方式来创造印象，特别是通过社交媒体渠道，如Twitter机器人和付费巨魔，最近，通过黑客攻击或复制你的朋友的帐户，某些错误的信念被广泛持有，包括你的朋友和其他人，你认同。甚至 PEACH的创造者也可能遇到过这种关于疫苗的合成讨论。根据2018年《美国公共卫生杂志》的一篇文章，这种造谣是由与俄罗斯影响行动有关的账户传播，这些账户试图扩大美国的不和，将公共卫生问题武器化。这种策略不是通过理性的论点或证据来改变思想，而只是通过操纵知识和信仰的社会传播来改变思想。<br>

错误信息工作的复杂程度（以及高度有针对性的造谣运动，放大了这些错误信息）对民主提出了一个令人不安的问题。以麻疹为例，许多州的儿童可以基于"个人信仰"而免于强制接种疫苗。2015年，在麻疹爆发后，这成为加州的一个热点，其追踪是未接种疫苗的儿童访问迪斯尼乐园。然后州长杰里布朗签署了一个新的法律，SB277，取消豁免。

疫苗怀疑论者立即提交文件，对下一次州投票进行全民公决，以推翻这项法律。如果他们成功地获得365，880个签名（他们只有233，758个签名），父母是否应该基于个人信仰而选择不进行强制接种疫苗的问题就会直接投票——其结果正是受到导致许多社区疫苗接种率急剧下降的各种造谣运动的影响。<br>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-9921197932759821"
     data-ad-slot="6363743541"></ins>

<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>



幸运的是，努力失败了。但是，数十万加州人支持就一个与公共卫生有严重关系的问题进行直接投票，因为事实清楚，但某些维权团体广泛误解，这一事实应该会严重停顿。我们关心的政策能够最好地反映现有证据，并响应可靠的新信息，这是有原因的。当这么多市民在事实上被误导时，我们如何保障公众的利益呢？正如根据错误信息行事的个人不太可能带来他们期望的结果一样，那些基于错误信仰的政策的社会也不太可能得到他们想要和期望的结果。<br>

决定科学事实问题的方法——疫苗是否安全有效——不是要求一个无专家社区投票表决，尤其是当他们受到错误信息宣传时。我们需要的是一个系统，它不仅尊重健全科学的进程和机构，作为我们了解世界真相的最佳方式，而且尊重核心民主价值观，这种价值观将排除科学家等单一群体支配政策。<br>

我们并没有建议建立一个能完全平衡这些相互竞争的问题的政府制度。但是我们认为关键是更好地区分两个本质上不同的问题：事实是什么，我们应该根据这些问题做什么？民主理想要求两者都需要公众监督、透明度和问责制。但这只是第二个——根据事实，我们应该如何作出决定——应该进行表决。<br><img class="img-fluid" src="images/qs-3.jpg" alt="Blog Image"/><br>
      </p>
      <p>In the mid-1800s a caterpillar the size of a human finger began spreading across the northeastern U.S. This appearance of the tomato hornworm was followed by terrifying reports of fatal poisonings and aggressive behavior toward people. In July 1869 newspapers across the region posted warnings about the insect, reporting that a girl in Red Creek, N.Y., had been “thrown into spasms, which ended in death” after a run-in with the creature. That fall the Syracuse Standard printed an account from one Dr. Fuller, who had collected a particularly enormous specimen. The physician warned that the caterpillar was “as poisonous as a rattlesnake” and said he knew of three deaths linked to its venom.
<br>
Although the hornworm is a voracious eater that can strip a tomato plant in a matter of days, it is, in fact, harmless to humans. Entomologists had known the insect to be innocuous for decades when Fuller published his dramatic account, and his claims were widely mocked by experts. So why did the rumors persist even though the truth was readily available? People are social learners. We develop most of our beliefs from the testimony of trusted others such as our teachers, parents and friends. This social transmission of knowledge is at the heart of culture and science. But as the tomato hornworm story shows us, our ability has a gaping vulnerability: sometimes the ideas we spread are wrong.<br>

Over the past five years the ways in which the social transmission of knowledge can fail us have come into sharp focus. Misinformation shared on social media Web sites has fueled an epidemic of false belief, with widespread misconceptions concerning topics ranging from the prevalence of voter fraud, to whether the Sandy Hook school shooting was staged, to whether vaccines are safe. The same basic mechanisms that spread fear about the tomato hornworm have now intensified—and, in some cases, led to—a profound public mistrust of basic societal institutions. One consequence is the largest measles outbreak in a generation.
<br>
“Misinformation” may seem like a misnomer here. After all, many of today's most damaging false beliefs are initially driven by acts of propaganda and disinformation, which are deliberately deceptive and intended to cause harm. But part of what makes propaganda and disinformation so effective in an age of social media is the fact that people who are exposed to it share it widely among friends and peers who trust them, with no intention of misleading anyone. Social media transforms disinformation into misinformation.<br>

Many communication theorists and social scientists have tried to understand how false beliefs persist by modeling the spread of ideas as a contagion. Employing mathematical models involves simulating a simplified representation of human social interactions using a computer algorithm and then studying these simulations to learn something about the real world. In a contagion model, ideas are like viruses that go from mind to mind. You start with a network, which consists of nodes, representing individuals, and edges, which represent social connections. You seed an idea in one “mind” and see how it spreads under various assumptions about when transmission will occur.<br>

Contagion models are extremely simple but have been used to explain surprising patterns of behavior, such as the epidemic of suicide that reportedly swept through Europe after publication of Goethe's The Sorrows of Young Werther in 1774 or when dozens of U.S. textile workers in 1962 reported suffering from nausea and numbness after being bitten by an imaginary insect. They can also explain how some false beliefs propagate on the Internet. Before the last U.S. presidential election, an image of a young Donald Trump appeared on Facebook. It included a quote, attributed to a 1998 interview in People magazine, saying that if Trump ever ran for president, it would be as a Republican because the party is made up of “the dumbest group of voters.” Although it is unclear who “patient zero” was, we know that this meme passed rapidly from profile to profile.<br>

The meme's veracity was quickly evaluated and debunked. The fact-checking Web site Snopes reported that the quote was fabricated as early as October 2015. But as with the tomato hornworm, these efforts to disseminate truth did not change how the rumors spread. One copy of the meme alone was shared more than half a million times. As new individuals shared it over the next several years, their false beliefs infected friends who observed the meme, and they, in turn, passed the false belief on to new areas of the network.<br>

This is why many widely shared memes seem to be immune to fact-checking and debunking. Each person who shared the Trump meme simply trusted the friend who had shared it rather than checking for themselves. Putting the facts out there does not help if no one bothers to look them up. It might seem like the problem here is laziness or gullibility—and thus that the solution is merely more education or better critical thinking skills. But that is not entirely right. Sometimes false beliefs persist and spread even in communities where everyone works very hard to learn the truth by gathering and sharing evidence. In these cases, the problem is not unthinking trust. It goes far deeper than that.<br>

TRUST THE EVIDENCE<br>

The contagion model is inadequate for answering this question. Instead we need a model that can capture cases where people form beliefs on the basis of evidence that they gather and share. It must also capture why these individuals are motivated to seek the truth in the first place. When it comes to health topics, there might be serious costs to acting on false beliefs. If vaccines are safe and effective (which they are) and parents do not vaccinate, they put their kids and immunosuppressed people at unnecessary risk. If vaccines are not safe, as the participants in these Facebook groups have concluded, then the risks go the other way. This means that figuring out what is true, and acting accordingly, matters deeply.
To better understand this behavior in our research, we drew on what is called the network epistemology framework. It was first developed by economists 20 years ago to study the social spread of beliefs in a community. Models of this kind have two parts: a problem and a network of individuals (or “agents”). The problem involves picking one of two choices: These could be “vaccinate” and “don't vaccinate” your children. In the model, the agents have beliefs about which choice is better. Some believe vaccination is safe and effective, and others believe it causes autism. Agent beliefs shape their behavior—those who think vaccination is safe choose to perform vaccinations. Their behavior, in turn, shapes their beliefs. When agents vaccinate and see that nothing bad happens, they become more convinced vaccination is indeed safe.
The second part of the model is a network that represents social connections. Agents can learn not only from their own experiences of vaccinating but also from the experiences of their neighbors. Thus, an individual's community is highly important in determining what beliefs they ultimately develop.<br><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-9921197932759821"
     data-ad-slot="6363743541"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
The network epistemology framework captures some essential features missing from contagion models: individuals intentionally gather data, share data and then experience consequences for bad beliefs. The findings teach us some important lessons about the social spread of knowledge. The first thing we learn is that working together is better than working alone, because an individual facing a problem like this is likely to prematurely settle on the worse theory. For instance, he or she might observe one child who turns out to have autism after vaccination and conclude that vaccines are not safe. In a community there tends to be some diversity in what people believe. Some test one action; some test the other. This diversity means that usually enough evidence is gathered to form good beliefs.<br>
But even this group benefit does not guarantee that agents learn the truth. Real scientific evidence is probabilistic, of course. For example, some nonsmokers get lung cancer, and some smokers do not get lung cancer. This means that some studies of smokers will find no connection to cancer. Relatedly, although there is no actual statistical link between vaccines and autism, some vaccinated children will be autistic. Thus, some parents observe their children developing symptoms of autism after receiving vaccinations. Strings of misleading evidence of this kind can be enough to steer an entire community wrong.
<br>
In the most basic version of this model, social influence means that communities end up at consensus. They decide either that vaccinating is safe or that it is dangerous. But this does not fit what we see in the real world. In actual communities, we see polarization—entrenched disagreement about whether or not to vaccinate. We argue that the basic model is missing two crucial ingredients: social trust and conformism.<br>

Social trust matters to belief when individuals treat some sources of evidence as more reliable than others. This is what we see when anti-vaxxers trust evidence shared by others in their community more than evidence produced by the Centers for Disease Control and Prevention or other medical research groups. This mistrust can stem from all sorts of things, including previous negative experiences with doctors or concerns that health care or governmental institutions do not care about their best interests. In some cases, this distrust may be justified, given that there is a long history of medical researchers and clinicians ignoring legitimate issues from patients, particularly women.<br>

Yet the net result is that anti-vaxxers do not learn from the very people who are collecting the best evidence on the subject. In versions of the model where individuals do not trust evidence from those who hold very different beliefs, we find communities polarize, and those with poor beliefs fail to learn better ones.<br>

Conformism, meanwhile, is a preference to act in the same way as others in one's community. The urge to conform is a profound part of the human psyche and one that can lead us to take actions we know to be harmful. When we add conformism to the model, what we see is the emergence of cliques of agents who hold false beliefs. The reason is that agents connected to the outside world do not pass along information that conflicts with their group's beliefs, meaning that many members of the group never learn the truth.<br>

Conformity can help explain why vaccine skeptics tend to cluster in certain communities. Some private and charter schools in southern California have vaccination rates in the low double digits. And rates are startlingly low among Somali immigrants in Minneapolis and Orthodox Jews in Brooklyn—two communities that have recently suffered from measles outbreaks.<br>

Interventions into vaccine skepticism need to be sensitive to both social trust and conformity. Simply sharing new evidence with skeptics will likely not help, because of trust issues. And convincing trusted community members to speak out for vaccination might be difficult because of conformism. The best approach is to find individuals who share enough in common with members of the relevant communities to establish trust. A rabbi, for instance, might be an effective vaccine ambassador in Brooklyn, whereas in southern California, you might need to get Gwyneth Paltrow involved.<br>

Social trust and conformity can help explain why polarized beliefs can emerge in social networks. But at least in some cases, including the Somali community in Minnesota and Orthodox Jewish communities in New York, they are only part of the story. Both groups were the targets of sophisticated misinformation campaigns designed by anti-vaxxers.
The PEACH handbook was especially effective because it combined selective sharing with rhetorical strategies. It built trust with Orthodox Jews by projecting membership in their community (though published pseudonymously, at least some authors were members) and emphasizing concerns likely to resonate with them. It cherry-picked facts about vaccines intended to repulse its particular audience; for instance, it noted that some vaccines contain gelatin derived from pigs. Wittingly or not, the pamphlet was designed in a way that exploited social trust and conformism—the very mechanisms crucial to the creation of human knowledge.<br>

Worse, propagandists are constantly developing ever more sophisticated methods for manipulating public belief. Over the past several years we have seen purveyors of disinformation roll out new ways of creating the impression—especially through social media conduits such as Twitter bots and paid trolls and, most recently, by hacking or copying your friends' accounts that certain false beliefs are widely held, including by your friends and others with whom you identify. Even the PEACH creators may have encountered this kind of synthetic discourse about vaccines. According to a 2018 article in the American Journal of Public Health, such disinformation was distributed by accounts linked to Russian influence operations seeking to amplify American discord and weaponize a public health issue. This strategy works to change minds not through rational arguments or evidence but simply by manipulating the social spread of knowledge and belief.
<br><img class="img-fluid" src="images/10-people.jpg" alt="Blog Image"/><br>
The sophistication of misinformation efforts (and the highly targeted disinformation campaigns that amplify them) raises a troubling problem for democracy. Returning to the measles example, children in many states can be exempted from mandatory vaccinations on the grounds of “personal belief.” This became a flash point in California in 2015 following a measles outbreak traced to unvaccinated children visiting Disneyland. Then governor Jerry Brown signed a new law, SB277, removing the exemption.
<br>
Immediately vaccine skeptics filed paperwork to put a referendum on the next state ballot to overturn the law. Had they succeeded in getting 365,880 signatures (they made it to only 233,758), the question of whether parents should be able to opt out of mandatory vaccination on the grounds of personal belief would have gone to a direct vote—the results of which would have been susceptible to precisely the kinds of disinformation campaigns that have caused vaccination rates in many communities to plummet.
<br>
Luckily, the effort failed. But the fact that hundreds of thousands of Californians supported a direct vote about a question with serious bearing on public health, where the facts are clear but widely misconstrued by certain activist groups, should give serious pause. There is a reason that we care about having policies that best reflect available evidence and are responsive to reliable new information. How do we protect public well-being when so many citizens are misled about matters of fact? Just as individuals acting on misinformation are unlikely to bring about the outcomes they desire, societies that adopt policies based on false belief are unlikely to get the results they want and expect.
<br>
The way to decide a question of scientific fact—are vaccines safe and effective?—is not to ask a community of nonexperts to vote on it, especially when they are subject to misinformation campaigns. What we need is a system that not only respects the processes and institutions of sound science as the best way we have of learning the truth about the world but also respects core democratic values that would preclude a single group, such as scientists, dictating policy.
<br>
We do not have a proposal for a system of government that can perfectly balance these competing concerns. But we think the key is to better separate two essentially different issues: What are the facts, and what should we do in light of them? Democratic ideals dictate that both require public oversight, transparency and accountability. But it is only the second—how we should make decisions given the facts—that should be up for a vote.</p>
    </div>
  </div>
</div>
<div class="pp-section"></div></div>
      </div>
      <footer class="pp-footer">
        <div class="container py-5">
          <div class="row text-center">
            <div class="col-md-12"><a class="pp-facebook btn btn-link" href="#"><i class="fa fa-facebook fa-2x " aria-hidden="true"></i></a><a class="pp-twitter btn btn-link " href="#"><i class="fa fa-twitter fa-2x " aria-hidden="true"></i></a><a class="pp-google-plus btn btn-link" href="#"><i class="fa fa-google-plus fa-2x" aria-hidden="true"></i></a><a class="pp-instagram btn btn-link" href="#"><i class="fa fa-instagram fa-2x " aria-hidden="true"></i></a></div>
            <div class="col-md-12">
              <p class="mt-3">Copyright &copy; 2019.Company name All rights reserved.<a target="_blank" href="http://www.aspku.com/moban/">&#x7F51;&#x9875;&#x6A21;&#x677F;</a></p>
            </div>
          </div>
        </div>
      </footer>
    </div>
	  <meta name=”Keywords” Content=”design,creat,设计,山合,picture,图片,art,艺术″

>
<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    

"@type": "Organization",
    "name": "Example",
    "url": 

"http://www.example.com",
    "logo": "http://www.example.com/images/logo.png"
  

}
</script>
<script src="//instant.page/5.1.0" type="module" integrity="sha384-

by67kQnR+pyfy8yWP4kPO12fHKRLHZPfEsiSXR8u2IKcTdxD805MGUXBzVPnkLHw"></script>
<script type="text/javascript" src="path/to/script1.js" async></script>
<script 

type="text/javascript" src="path/to/script2.js" async></script>
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

    <script src="js/jquery-3.2.1.min.js"></script>
    <script src="js/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="scripts/main.js"></script>
  </body>
</html>